from dotenv import load_dotenv
import os
import requests
from youtube_transcript_api import YouTubeTranscriptApi
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain

# https://pypi.org/project/youtube-transcript-api/
# transcript = YouTubeTranscriptApi.get_transcript(youtube_ids[1], languages=['en'])
# transcript_list = YouTubeTranscriptApi.list_transcripts(youtube_ids[4])
# transcript = transcript_list.find_manually_created_transcript(['en'])
# print(transcript.fetch())

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.0)

search_terms_prompt = PromptTemplate(
    input_variables=["text_input"],
    template="I want you to give me a single good youtube search query based on the following prompt:\n\n {text_input}"
)

YT_create_search_terms_chain = LLMChain(llm=llm, prompt=search_terms_prompt)


def get_yt_videos(query: str, max_results: int) -> list:
    """
    arguments:
    query: The search term generated by the agent based upon your prompt
    max_results: number of youtube videos to process

    returns a list video id's of the top n results from the search query the agent inputs 
    """

    # Get youtube API key
    load_dotenv()
    api_key = os.environ['yt_api_key'] 

    # Create search url
    base_url = 'https://www.googleapis.com/youtube/v3/'
    search_url = f'{base_url}search?key={api_key}&q={query}&maxResults={max_results}&part=snippet&type=video'
    
    # Send the GET request to the API.
    response = requests.get(search_url)

    #Fetch data
    data = response.json()
    items = data['items']
    return [item['id']['videoId'] for item in items]



def fetch_transcript(video :str) -> str:
    """
    arguments:
    video: id of the video

    returns english transcript of the video 
    """

    # https://pypi.org/project/youtube-transcript-api/

    #Get available languages
    transcript_list = YouTubeTranscriptApi.list_transcripts(video)

    # TO DO: Add if statements to do something else when english transcript is not available
    #filter for english transcript
    transcript = transcript_list.find_transcript(['en']).fetch()

    text_transcript = [chunk['text'] for chunk in transcript]
    
    return ' '.join(text_transcript)




